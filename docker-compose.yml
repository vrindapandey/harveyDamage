#version: '3'
#services:
#  model-inference-server:
#    image: <your-dockerhub-username>/model-inference-server
#    ports:
#      - "5000:5000"
#    environment:
#      - TF_CPP_MIN_LOG_LEVEL=2
#    restart: always

version: "3"
services:
  inference:
    build:
      context: .
    image: vrindapandey/model-inference-server
    ports:
      - "5000:5000"
    volumes:
      - ./data:/data
