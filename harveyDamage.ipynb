{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f68e50d-caef-45ab-ae56-77fe7ef77caa",
   "metadata": {},
   "source": [
    "Part 1: (3 points) Data preprocessing and visualization\r\n",
    "\r\n",
    "You will need to perform data analysis and pre-processing to prepare the images for training. At a minimum, you shoul \r\n",
    "\r\n",
    "Write code to load the data into Python data structures\r\n",
    "\r\n",
    "Investigate the datasets to determine basic attributes of the images\r\n",
    "\r\n",
    "Ensure data is split for training, validation and testing and perform any additional preprocessing (e.g., rescaling, normalization, etc.) so that it can be used for training/evaluation of the neural networks you will build in Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024bccd-5c9c-4add-be4e-338d63cf0eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ee4dc1e-ade3-4942-b0cb-2425e9df423c",
   "metadata": {},
   "source": [
    "Part 2: (10 points) Model design, training and evaluation\r\n",
    "\r\n",
    "You will explore different model architectures that we have seen in class, including:\r\n",
    "\r\n",
    "A dense (i.e., fully connected) ANN\r\n",
    "\r\n",
    "The Lenet-5 CNN architecture\r\n",
    "\r\n",
    "Alternate-Lenet-5 CNN architecture, described in the following paper (Table 1, Page 12 of the research paper https://arxiv.org/pdf/1807.01688.pdf, but note that the dataset is not the same as that analyzed in thed in the paper.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89ffd7-ebfc-406f-a335-81ae10449d74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e214211-5c5e-4356-b9ad-aeea07edb04a",
   "metadata": {},
   "source": [
    "Part 3: (7 points) Model inference server and deployment **help class site MLOps -> developing an inference server in flask\r\n",
    "\r\n",
    "For the best model built in part 2, persist the trained model to disk so that it can be reconstituted easily. Develop a simple inference server to serve your trained model over HTTP. There should be at least two endpoints:\r\n",
    "\r\n",
    "A model summary endpoint GET /summary providing metadata about the model.\r\n",
    "\r\n",
    "Note: This endpoint must be accept requests to: GET /summary and it must return a JSON response.\r\n",
    "\r\n",
    "An inference endpoint POST /inference that can perform classification on a\n",
    "\n",
    "#cannot build docker image in jupyter server (use command line on VM)\n",
    "everything in your notebook should be on machine in nb-data\n",
    "\n",
    "Dockerfile and api.py can be created in notebook but docker build and docker commands (run) cant be in jupter\n",
    "\n",
    "\n",
    "unit 3 for project have to do option 1\n",
    "1/ Requre the user send a raw image file, such as a png or jpgn image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d4bd44-bf58-46fa-96f7-d4837fbb4396",
   "metadata": {},
   "source": [
    "Part 4: (7 points) Write a 3 page report summarizing your work. (info on class page)) (1 pt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
